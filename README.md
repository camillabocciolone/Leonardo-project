
# Leonardo-project ‚Äî EEGPT vs FDA (LL2 EEG)

Questo repository contiene notebook Colab per confrontare un **foundation model EEG (EEGPT)** con una **baseline FDA / PCA** e con **baseline spettrali (bandpower)** sul dataset LL2 (EEG workload).

## Contenuto

- **`eegpt_vs_FDA.ipynb`**  
  Notebook principale: pipeline completa per
  - caricamento + preprocessing + windowing
  - split subject-independent (recording-level / LOSO)
  - estrazione embedding EEGPT
  - feature FDA (PCA per-canale e PCA globale)
  - classificatore downstream (MLP) + confusion matrix
  - visualizzazioni (t-SNE/[UMAP])

- **`ll2egpt.ipynb`**  
  Notebook di esperimenti/miglioramenti per EEGPT:
  - tuning parametri patch/stride
  - test su robust z-score (MAD) per epoca
  - separazione task (Arithmetic vs Stroop)
  - controlli su preprocessing / timestamp / interpolazione
  - analisi diagnostiche
 
- **`baselinebandpower.ipynb`**  
  Scopo principale:
  - usare baseline bandpower / relative bandpower per capire quanti classi considerare e se il preprocessing √® adeguato
  4 contesti:
    1) preprocessing senza fare interpolazione e 4 classi
    2) preprocessing con interpolazione e 4 classi
    3) preprocessing senza fare interpolazione e 3 classi
    4) preprocessing con interpolazione e 3 classi
  - risulta che la combinazione migliore sia preprocessing senza fare interpolazione e 3 classi
  - sicuramente si considerassero 2 classi sarebbe ancore migliore la predizione

---

## Setup rapido (Colab)

### 1) Monta Google Drive
Nel notebook √® previsto il mount:
```python
from google.colab import drive
drive.mount('/content/drive')
````

### 2) Dataset (path atteso)

I notebook assumono che i file siano disponibili in una cartella tipo:

```
/content/drive/MyDrive/LL2/LL2/raw_data/
```

Sono supportati i due layout:

* `{level}_Data/{task}-{subject}.txt`
* `{task}_Data/{level}-{subject}.txt`

Esempi:

* `Stroop_Data/midlevel-7.txt`
* `midlevel_Data/Stroop-7.txt`

> Se il tuo path √® diverso, modifica la variabile `data_dir` nel notebook.

### 3) Checkpoint EEGPT

Il checkpoint viene letto da Drive, ad esempio:

```
/content/drive/MyDrive/EEGPT/checkpoint/eegpt_mcae_58chs_4s_large4E.ckpt
```

---

## Pipeline (in breve)

1. **Preprocessing**

   * bandpass (default 0.5‚Äì45 Hz)
   * notch 50 Hz
   * detrend
   * clip robusto (quantile)
   * resampling 250 ‚Üí 256 Hz
   * epoching 4s con stride 2s

2. **Split**

   * baseline: split recording-level con vincolo subject-independent
   * TODO/next: LOSO puro (Leave-One-Subject-Out) su tutti i soggetti

3. **Feature extraction**

   * **EEGPT**: `forward_features` ‚Üí embedding per finestra ‚Üí pooling per recording
   * **FDA/PCA**:

     * per-canale: PCA su 1024 campioni per canale, K PC per canale ‚Üí 8K feature
     * globale: PCA su vettore (8√ó1024) ‚Üí K feature
   * **Bandpower baseline**:

     * log bandpower in delta/theta/alpha/beta per canale
     * opzionale: relative bandpower

4. **Downstream classifier**

   * MLP (stesso classificatore per confronti fair)
   * confusion matrix + classification report
   * visualizzazioni: t-SNE / UMAP (record-level o window-level)

---

## Note importanti (per evitare leakage)

* La valutazione deve rimanere **subject-independent**:

  * tutte le finestre dello stesso soggetto/recording devono stare nello stesso split
* Le trasformazioni tipo PCA/standardizzazione vanno **fit solo sul train** e applicate a val/test.

---

## Obiettivo del progetto

Valutare se, in regime **low-data** (pochi soggetti), un foundation model EEG fornisce vantaggi rispetto a:

* baseline classiche e interpretabili (FDA/PCA)
* baseline spettrali (bandpower)

e usare FDA anche come supporto interpretativo (feature comprensibili / correlazioni con output).

---

## Dipendenze principali

I notebook installano automaticamente (in Colab):

* `numpy`, `scipy`, `scikit-learn`, `torch`
* `einops`, `tqdm`
* (opzionale) `umap-learn` per UMAP

## idea  confronto

1Ô∏è‚É£ Segnale EEG (finestre)
Ogni finestra √® un segnale nel tempo (8 canali √ó 1024 punti)
Questo √® il livello pi√π ‚Äúgrezzo‚Äù
2Ô∏è‚É£ FDA ‚Üí FPC (questo √® il cuore)
Con l‚ÄôFDA fai due cose distinte:
a) FPC (le componenti)
Sono funzioni del tempo
Descrivono come il segnale pu√≤ variare:
oscillazioni lente
oscillazioni pi√π rapide
cambi di ampiezza, ecc.
Sono globali, non appartengono a un soggetto
b) Score FPC
Per ogni finestra (o recording) ottieni dei numeri:
‚Äúquanto questo segnale segue la FPC1, la FPC2, ‚Ä¶‚Äù
Questi cambiano:
da finestra a finestra
da recording a recording
da soggetto a soggetto
üëâ Questi numeri sono le feature FDA
3Ô∏è‚É£ EEGPT
EEGPT:
prende le stesse finestre EEG
produce:
embedding
oppure direttamente probabilit√† di classe
EEGPT √® una scatola nera:
non sai perch√© decide una classe
sai solo quanto √® sicuro
üîë L‚ÄôIDEA DI INTERPRETAZIONE (questa √® la chiave)
Ci facciamo questa domanda:
Quando EEGPT dice ‚Äúclasse X con alta probabilit√†‚Äù,
quali modalit√† temporali del segnale stanno aumentando?
Tradotto:
EEGPT usa di pi√π segnali con:
oscillazioni lente?
oscillazioni rapide?
ampiezza alta?
Queste cose sono esattamente ci√≤ che catturano le FPC
üëâ Quindi:
correlo gli score delle FPC con le probabilit√† EEGPT
Se c‚Äô√® correlazione:
EEGPT non √® magico
sta sfruttando strutture temporali precise

---

## Contatti

Camilla Bocciolone



